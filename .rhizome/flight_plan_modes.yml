# vscode-rhizome Flight Plan Modes
#
# How we think about extension development through don-socratic phases.
# Each mode reflects the kind of thinking needed at that stage of building
# a VSCode extension using teaching-first principles.
#
# Reference: don-socratic_persona.md
#
# This file demonstrates how flight_plan_modes can be customized per repository
# to match how that specific project thinks about work.

modes:
  kitchen_table:
    name: Kitchen Table
    archetypal_question: "What are we actually building, and why does it matter?"

    description: |
      Design & vision phase for vscode-rhizome. Before writing a single line,
      we sit with the problem: What does a don-socratic extension *feel* like
      to use? How does it invite questioning without being pushy? What edge
      cases will break the teaching experience?

      This phase answers: "What would make this extension *worth* having?"

    thinking_patterns:
      - name: "User Experience First"
        question: "How does a developer experience this moment? What are they thinking?"
        purpose: "Design for the person, not the feature"
        example: "When they mark @rhizome stub, what's happening in their head? Stress? Excitement? Confusion?"

      - name: "Teaching Through Friction"
        question: "Where should this code be intentionally rough? Where should it invite refactoring?"
        purpose: "Code comments become curriculum"
        example: "Each function has a don-socratic question embedded. Rough edges are teaching moments."

      - name: "Map the AI Integration"
        question: "Which parts need AI? Which parts should be deterministic? Where's the fallback?"
        purpose: "Know where we're dependent on external services"
        example: "Stub generation (deterministic, no AI) vs. querying (AI-powered, needs fallback)"

      - name: "Define Success Criteria"
        question: "How will a developer know this extension is working? How will we know we're teaching?"
        purpose: "Know what 'done' looks like before we build it"
        example: "Test scenarios define success: both stub generation AND don-socratic querying work end-to-end"

      - name: "Identify Teaching Moments"
        question: "What should a developer learn by reading this code? Where are the 'aha' moments?"
        purpose: "Architecture serves pedagogy"
        example: "test-utils.ts extracts 4 patterns; developer learns by using them; seeing them again feels familiar"

    persona_modes:
      una:
        mode: "guide"
        role: "Clarity Guardian"
        question: "Are we being clear about what experience we're creating?"
        contribution: "Asks sharp questions about UX, pushes on assumptions, ensures design documents are precise"

      bro:
        mode: "challenger"
        role: "Reality Scout"
        question: "What could go wrong from the user's perspective? What edge cases break the teaching?"
        contribution: "Tests scenarios, imagines failure modes, pushes on feature scope"

      root:
        mode: "reasoner"
        role: "Pattern Witness"
        question: "Have we seen this pattern before? How does this fit with how VSCode extensions typically work?"
        contribution: "Brings vscode ecosystem knowledge, connects to prior examples, flags architectural misalignment"

    exit_criteria:
      - "Extension UX is sketched and agreed (what does stub generation feel like?)"
      - "AI integration boundaries are clear (what's deterministic vs. service-dependent)"
      - "Test scenarios are defined and written (what are we trying to teach?)"
      - "Teaching moments are identified (where should code be rough?)"
      - "Success metrics are known (how will we measure this works?)"
      - "Ready to implement: architecture is clear, not perfect"

    anti_patterns:
      - "Building before sketching what it *feels* like to use"
      - "Hiding complexity instead of using it as teaching moment"
      - "Making decisions about AI integration without testing fallbacks"
      - "Forgetting this is a teaching tool, not just a productivity tool"
      - "Polishing code before verifying core experience works"

  garden:
    name: Garden
    archetypal_question: "What does the evidence show us? What's actually working?"

    description: |
      Implementation & testing phase. We plant the design, tend it carefully,
      observe what actually happens vs. what we predicted, and adjust.

      Garden work for vscode-rhizome means: implement features, run test scenarios,
      watch real developers use it, capture what breaks and what delights.

    thinking_patterns:
      - name: "Build Testable First"
        question: "Can we test this before it's polished? What's the minimal thing?"
        purpose: "Get real feedback on whether our design works"
        example: "Stub generation without UI polish; test the AST parsing first"

      - name: "Observe and Document"
        question: "What's happening that we didn't predict? What surprised us?"
        purpose: "Learn from reality, not theory"
        example: "Edge case: Python indentation rules are different; we discover this in testing, not shipping"

      - name: "Test Both Paths"
        question: "What works when everything's ideal? What fails gracefully?"
        purpose: "Ensure extension is reliable and kind on error"
        example: "Happy path: OpenAI key exists, rhizome init done. Error path: no key, no context."

      - name: "Extract Patterns"
        question: "Are we repeating code? Should this become a helper?"
        purpose: "Keep code DRY; make test utils reusable for next feature"
        example: "Three tests doing setup → assert → teardown; extract TestWorkspace"

      - name: "Verify Teaching Works"
        question: "Does reading this code teach what we intended? Does the friction help?"
        purpose: "Refactor for clarity and intentional roughness"
        example: "Code review: 'This function is confusing. Good. Leave it and add a better comment question.'"

    persona_modes:
      una:
        mode: "witness"
        role: "Evidence Keeper"
        question: "What are we actually seeing? What does the test log show?"
        contribution: "Documents test results, compares to design, flags misalignment"

      bro:
        mode: "executor"
        role: "Builder"
        question: "What's the next concrete thing to implement? What's blocking us?"
        contribution: "Moves work forward, solves technical puzzles, unblocks testing"

      root:
        mode: "skeptic"
        role: "Reality Check"
        question: "Does this match what we said we'd build? Are we teaching what we intended?"
        contribution: "Compares implementation to kitchen_table design, flags scope creep, validates assumptions"

    exit_criteria:
      - "Stub generation works for TypeScript and Python; edge cases handled"
      - "Don-socratic querying tested with and without OpenAI key"
      - "Error paths all handled gracefully (no silent failures)"
      - "Test scenarios from kitchen_table are all automated"
      - "test-utils.ts extracted and documented"
      - "Code is intentionally rough where it teaches; polished where it shouldn't be"
      - "Ready to release: teaching experience verified, not perfect"

    anti_patterns:
      - "Building without testing immediately"
      - "Hiding error cases instead of handling them gracefully"
      - "Polishing code before verifying core features work"
      - "Forgetting the teaching purpose while building"
      - "Testing only happy path; ignoring fallbacks"

  library:
    name: Library
    archetypal_question: "What does this teach? How does it fit the ecosystem?"

    description: |
      Learning & synthesis phase. The extension works. Now we document why,
      extract patterns, connect to prior work, and make it discoverable for
      future developers (and AI agents reading the code).

      Library work means: write docs, record teaching moments, catalog patterns,
      prepare for next person to extend it.

    thinking_patterns:
      - name: "Document the Why"
        question: "Why did we make this choice? What trade-off were we accepting?"
        purpose: "Future maintainers understand the full picture"
        example: "We use AST parsing for JS/TS but regex for Python. Why? Trade-off doc explains."

      - name: "Extract Teaching Moments"
        question: "Where's the rough code intentional? What should someone learn from reading it?"
        purpose: "Convert implicit teaching into explicit guidance"
        example: "Catalog the comment-questions; they're a curriculum in themselves"

      - name: "Connect to Ecosystem"
        question: "How does this pattern appear in other vscode extensions? What can we learn from them?"
        purpose: "Build organizational knowledge"
        example: "Stub generation inspired by Jest snapshot testing; here's how they differ"

      - name: "Catalog Patterns"
        question: "What's reusable here? Where would these patterns appear again?"
        purpose: "Enable reuse; build library of solutions"
        example: "TestWorkspace, MockRhizome, TestAssertions become templates for next vscode tool"

      - name: "Identify Next Questions"
        question: "What did building this raise that we didn't have time for?"
        purpose: "Seed future work; connect discoveries"
        example: "Could we extend don-socratic querying to suggest refactors? Should we?"

    persona_modes:
      una:
        mode: "advocate"
        role: "Chronicler"
        question: "What's the story here? Why should someone care about this approach?"
        contribution: "Writes clearly, connects to bigger picture, makes learning visible"

      bro:
        mode: "balance"
        role: "Pragmatist"
        question: "What was worth the effort? What did we over-engineer?"
        contribution: "Evaluates trade-offs honestly, identifies what to simplify in next iteration"

      root:
        mode: "reasoner"
        role: "Synthesizer"
        question: "What principles emerge? How does this fit the don-socratic philosophy?"
        contribution: "Finds patterns, connects to other work, surfaces why this matters"

    exit_criteria:
      - "Design decisions documented with rationale (why AST vs. regex?)"
      - "Teaching moments catalogued (where's the friction? What's it teaching?)"
      - "Patterns identified for reuse (test-utils.ts, stub generation, query pattern)"
      - "Ecosystem connections documented (how does this compare to similar tools?)"
      - "Next improvements are clear (full refactoring? New feature? Simplification?)"
      - "New developer can understand the work (README, architecture doc, code comments)"
      - "This work is now part of vscode-rhizome's institutional knowledge"

    anti_patterns:
      - "Rushing to ship; no time for documentation"
      - "Documenting only successes, hiding what didn't work"
      - "Writing docs no one will read (missing audience)"
      - "Treating library phase as optional/luxury/low-priority"
      - "Forgetting that teaching is the point; treating it as afterthought"

# Transitions between modes
transitions:
  kitchen_table_to_garden:
    signal: "Design is clear; test scenarios written; ready to build"
    question: "Are we ready to test this in reality?"
    conductor_responsibility: "Ensure everyone understands what we're building; check that test scenarios match design"

  garden_to_library:
    signal: "Core features work; test suite is passing; rough code is intentional"
    question: "What does this teach us? How do we want others to learn from this?"
    conductor_responsibility: "Protect reflection time; resist pressure to immediately start new feature"

  library_to_kitchen_table:
    signal: "New feature discovered during learning; design implications are big"
    question: "Is this new work or refinement of current work?"
    conductor_responsibility: "Name what changed; determine if it affects current design or belongs to next flight"

# Metadata for each mode
metadata:
  kitchen_table:
    typical_duration: "1-2 days"
    minimum_participants: 2
    outputs: ["design doc", "UX sketch", "test scenarios", "architecture notes"]
    tools: "whiteboard, markdown, discussion"

  garden:
    typical_duration: "3-7 days"
    minimum_participants: 1
    outputs: ["working code", "test suite", "edge case log", "rough spots intentional"]
    tools: "TypeScript/Python IDE, test runner, git, vscode debugger"

  library:
    typical_duration: "1-2 days"
    minimum_participants: 2
    outputs: ["design decision records", "teaching catalog", "pattern extraction", "next questions"]
    tools: "markdown, discussion, code review"

# vscode-rhizome specifics
project_context:
  project_name: "vscode-rhizome"
  purpose: "VSCode extension bringing don-socratic questioning into code editing"
  key_features:
    - "Stub generation (@rhizome stub marker → TODO + error throw)"
    - "Don-socratic querying (select code → ask questions via rhizome CLI)"
  teaching_focus: |
    This is not just a productivity tool; it's a teaching tool.
    Every decision, every rough edge, every test is intentional.
    Code comments are curriculum. Test structure is pedagogy.
  audience: |
    - Developers learning VSCode extension patterns
    - Teams adopting don-socratic thinking
    - Future maintainers extending this tool